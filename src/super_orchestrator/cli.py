"""Typer CLI for the Super Orchestrator pipeline.

Provides 8 commands:

- ``init``      -- initialize a new pipeline run
- ``plan``      -- run the architect phase
- ``build``     -- run the builder fleet
- ``integrate`` -- run the integration phase
- ``verify``    -- run the quality gate
- ``run``       -- execute the full pipeline end-to-end
- ``status``    -- display current pipeline state
- ``resume``    -- resume an interrupted pipeline

Each command that performs async work wraps a single
``asyncio.run(_async_impl())`` call -- exactly one event loop per
CLI invocation (TECH-029).
"""

from __future__ import annotations

import asyncio
import logging
import shutil
import subprocess
import sys
from pathlib import Path
from typing import Annotated, Optional

import typer

import src.build3_shared as _b3
from src.build3_shared.constants import ALL_PHASES, STATE_DIR, STATE_FILE
from src.build3_shared.utils import ensure_dir
from src.super_orchestrator.config import (
    SuperOrchestratorConfig,
    load_super_config,
)
from src.super_orchestrator.display import (
    print_builder_table,
    print_error_panel,
    print_final_summary,
    print_phase_table,
    print_pipeline_header,
    print_quality_summary,
)
from src.super_orchestrator.exceptions import (
    ConfigurationError,
    PipelineError,
)
from src.super_orchestrator.state import PipelineState

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Typer app (TECH-028: rich_markup_mode="rich")
# ---------------------------------------------------------------------------

app = typer.Typer(
    name="super-orchestrator",
    help="[bold]Super Orchestrator[/bold] â€” Build 3 pipeline CLI",
    rich_markup_mode="rich",
    add_completion=False,
)


# ---------------------------------------------------------------------------
# Version callback
# ---------------------------------------------------------------------------


def _version_callback(value: bool) -> None:
    """Print version and exit."""
    if value:
        typer.echo(f"super-orchestrator {_b3.__version__}")
        raise typer.Exit()


@app.callback()
def main(
    version: Annotated[
        bool,
        typer.Option(
            "--version",
            "-V",
            help="Show version and exit.",
            callback=_version_callback,
            is_eager=True,
        ),
    ] = False,
) -> None:
    """Super Orchestrator Build 3 pipeline."""


# ---------------------------------------------------------------------------
# Default config template
# ---------------------------------------------------------------------------

_DEFAULT_CONFIG_TEMPLATE = """\
# Super Orchestrator Configuration
# Generated by: super-orchestrator init

# Architect phase settings
architect:
  timeout: 300        # seconds
  retries: 2          # max retry attempts
  mcp_server: architect  # MCP server name

# Builder phase settings
builder:
  max_concurrent: 3   # max parallel builders
  timeout: 1800       # per-builder timeout (seconds)
  depth: thorough     # build depth: quick, standard, thorough

# Integration phase settings
integration:
  compose_timeout: 120    # docker compose timeout (seconds)
  health_timeout: 60      # service health check timeout (seconds)
  traefik_image: "traefik:v3.6"  # Traefik docker image

# Quality gate settings
quality_gate:
  max_fix_retries: 3   # max fix pass iterations
  layer_timeout: 300   # per-layer timeout (seconds)

# Global settings
budget_limit: 50.0     # max spend in USD
output_dir: ".super-orchestrator"  # pipeline output directory
"""


# ---------------------------------------------------------------------------
# Commands
# ---------------------------------------------------------------------------


@app.command()
def init(
    prd_path: Annotated[
        Path,
        typer.Argument(
            help="Path to the PRD file.",
            exists=True,
            readable=True,
        ),
    ],
    output_dir: Annotated[
        Path,
        typer.Option(
            "--output-dir",
            "-o",
            help="Output directory for pipeline artifacts.",
        ),
    ] = Path("."),
) -> None:
    """Initialize a new pipeline run from a PRD file.

    Validates the PRD, creates the .super-orchestrator directory,
    copies the PRD, generates a default config, and checks Docker.
    """
    # Validate PRD size (> 100 bytes)
    prd_size = prd_path.stat().st_size
    if prd_size <= 100:
        print_error_panel(
            f"PRD file is too small ({prd_size} bytes). "
            "Must be greater than 100 bytes."
        )
        raise typer.Exit(code=1)

    # Create .super-orchestrator directory
    state_dir = output_dir / STATE_DIR
    ensure_dir(state_dir)

    # Copy PRD to output directory
    prd_dest = state_dir / "prd.md"
    shutil.copy2(str(prd_path), str(prd_dest))

    # Initialize pipeline state
    state = PipelineState(
        prd_path=str(prd_dest),
    )
    state.save(state_dir / "PIPELINE_STATE.json")

    # Generate default config.yaml if not exists
    config_path = output_dir / "config.yaml"
    if not config_path.exists():
        config_path.write_text(_DEFAULT_CONFIG_TEMPLATE, encoding="utf-8")
        typer.echo(f"Generated default config: {config_path}")

    # Check Docker availability
    docker_ok = _check_docker()
    if not docker_ok:
        typer.echo(
            "[yellow]Warning: Docker Compose not available. "
            "Integration phase will not work.[/yellow]"
        )

    typer.echo(f"Pipeline initialized: {state.pipeline_id}")
    typer.echo(f"State directory: {state_dir}")
    typer.echo(f"PRD copied to: {prd_dest}")

    print_pipeline_header(state.pipeline_id, str(prd_path))


@app.command()
def plan(
    system: Annotated[
        str,
        typer.Option("--system", "-s", help="System to plan ('all' or service name)."),
    ] = "all",
    config_path: Annotated[
        Optional[Path],
        typer.Option("--config", "-c", help="Path to config YAML."),
    ] = None,
) -> None:
    """Run the Architect phase to decompose the PRD.

    Loads existing pipeline state and runs only the architect phase.
    """
    asyncio.run(_plan_async(system, config_path))


async def _plan_async(system: str, config_path: Path | None) -> None:
    """Async implementation of the plan command."""
    from src.super_orchestrator.cost import PipelineCostTracker
    from src.super_orchestrator.pipeline import run_architect_phase
    from src.super_orchestrator.shutdown import GracefulShutdown

    try:
        state = PipelineState.load()
    except FileNotFoundError:
        print_error_panel("No pipeline state found. Run 'init' first.")
        raise typer.Exit(code=1)

    config = load_super_config(config_path)
    cost_tracker = PipelineCostTracker(budget_limit=config.budget_limit)
    shutdown = GracefulShutdown()

    try:
        await run_architect_phase(state, config, cost_tracker, shutdown)
        typer.echo("Architect phase complete.")
        print_phase_table(state)
    except PipelineError as exc:
        print_error_panel(str(exc))
        raise typer.Exit(code=1)


@app.command()
def build(
    parallel: Annotated[
        bool,
        typer.Option("--parallel/--sequential", help="Run builders in parallel."),
    ] = True,
    system: Annotated[
        Optional[list[int]],
        typer.Option("--system", "-s", help="Specific system indices to build."),
    ] = None,
    max_concurrent: Annotated[
        int,
        typer.Option("--max-concurrent", "-j", help="Max concurrent builders."),
    ] = 3,
    config_path: Annotated[
        Optional[Path],
        typer.Option("--config", "-c", help="Path to config YAML."),
    ] = None,
) -> None:
    """Run the Builder fleet to build services.

    Launches builder subprocesses for each service defined in the
    service map.
    """
    asyncio.run(_build_async(parallel, system, max_concurrent, config_path))


async def _build_async(
    parallel: bool,
    system: list[int] | None,
    max_concurrent: int,
    config_path: Path | None,
) -> None:
    """Async implementation of the build command."""
    from src.super_orchestrator.cost import PipelineCostTracker
    from src.super_orchestrator.pipeline import run_parallel_builders
    from src.super_orchestrator.shutdown import GracefulShutdown

    try:
        state = PipelineState.load()
    except FileNotFoundError:
        print_error_panel("No pipeline state found. Run 'init' first.")
        raise typer.Exit(code=1)

    config = load_super_config(config_path)
    if max_concurrent != 3:
        config.builder.max_concurrent = max_concurrent
    cost_tracker = PipelineCostTracker(budget_limit=config.budget_limit)
    shutdown = GracefulShutdown()

    try:
        await run_parallel_builders(state, config, cost_tracker, shutdown)
        print_builder_table(state)
    except PipelineError as exc:
        print_error_panel(str(exc))
        raise typer.Exit(code=1)


@app.command()
def integrate(
    compose_file: Annotated[
        Optional[Path],
        typer.Option("--compose-file", "-f", help="Path to docker-compose file."),
    ] = None,
    config_path: Annotated[
        Optional[Path],
        typer.Option("--config", "-c", help="Path to config YAML."),
    ] = None,
) -> None:
    """Run the Integration phase (Docker + compliance + cross-service tests).

    Deploys services via Docker Compose, runs contract compliance
    checks, and executes cross-service test flows.
    """
    asyncio.run(_integrate_async(compose_file, config_path))


async def _integrate_async(compose_file: Path | None, config_path: Path | None) -> None:
    """Async implementation of the integrate command."""
    from src.super_orchestrator.cost import PipelineCostTracker
    from src.super_orchestrator.pipeline import run_integration_phase
    from src.super_orchestrator.shutdown import GracefulShutdown

    try:
        state = PipelineState.load()
    except FileNotFoundError:
        print_error_panel("No pipeline state found. Run 'init' first.")
        raise typer.Exit(code=1)

    config = load_super_config(config_path)
    cost_tracker = PipelineCostTracker(budget_limit=config.budget_limit)
    shutdown = GracefulShutdown()

    try:
        await run_integration_phase(state, config, cost_tracker, shutdown)
        typer.echo("Integration phase complete.")
        print_phase_table(state)
    except PipelineError as exc:
        print_error_panel(str(exc))
        raise typer.Exit(code=1)


@app.command()
def verify(
    fix: Annotated[
        bool,
        typer.Option("--fix/--no-fix", help="Run fix pass if gate fails."),
    ] = True,
    layer: Annotated[
        Optional[int],
        typer.Option("--layer", "-l", help="Run only a specific layer (1-4)."),
    ] = None,
    config_path: Annotated[
        Optional[Path],
        typer.Option("--config", "-c", help="Path to config YAML."),
    ] = None,
) -> None:
    """Run the Quality Gate verification.

    Executes the 4-layer quality gate engine and optionally runs
    fix passes for failing services.
    """
    asyncio.run(_verify_async(fix, layer, config_path))


async def _verify_async(fix: bool, layer: int | None, config_path: Path | None) -> None:
    """Async implementation of the verify command."""
    from src.super_orchestrator.cost import PipelineCostTracker
    from src.super_orchestrator.pipeline import run_quality_gate
    from src.super_orchestrator.shutdown import GracefulShutdown

    try:
        state = PipelineState.load()
    except FileNotFoundError:
        print_error_panel("No pipeline state found. Run 'init' first.")
        raise typer.Exit(code=1)

    config = load_super_config(config_path)
    cost_tracker = PipelineCostTracker(budget_limit=config.budget_limit)
    shutdown = GracefulShutdown()

    try:
        report = await run_quality_gate(state, config, cost_tracker, shutdown)
        print_quality_summary(report)
    except PipelineError as exc:
        print_error_panel(str(exc))
        raise typer.Exit(code=1)


@app.command(name="run")
def run_cmd(
    prd_path: Annotated[
        Path,
        typer.Argument(
            help="Path to the PRD file.",
            exists=True,
            readable=True,
        ),
    ],
    resume_flag: Annotated[
        bool,
        typer.Option("--resume", "-r", help="Resume from interrupted state."),
    ] = False,
    config_path: Annotated[
        Optional[Path],
        typer.Option("--config", "-c", help="Path to config YAML."),
    ] = None,
) -> None:
    """Execute the full pipeline end-to-end.

    Takes a PRD file, orchestrates all phases (architect, contracts,
    builders, integration, quality gate, fix passes), and produces
    the final result.
    """
    asyncio.run(_run_async(prd_path, resume_flag, config_path))


async def _run_async(
    prd_path: Path, resume_flag: bool, config_path: Path | None
) -> None:
    """Async implementation of the run command."""
    from src.super_orchestrator.pipeline import execute_pipeline

    config = load_super_config(config_path)
    config_path_str = str(config_path) if config_path else None

    print_pipeline_header(
        "pending" if not resume_flag else "resuming",
        str(prd_path),
    )

    try:
        state = await execute_pipeline(
            prd_path=prd_path,
            config_path=config_path_str,
            resume=resume_flag,
        )
        print_final_summary(state)
    except PipelineError as exc:
        print_error_panel(str(exc))
        # Try to show final summary if state exists
        try:
            state = PipelineState.load()
            print_final_summary(state)
        except Exception:
            pass
        raise typer.Exit(code=1)
    except KeyboardInterrupt:
        typer.echo("\n[yellow]Pipeline interrupted. State saved.[/yellow]")
        try:
            state = PipelineState.load()
            print_final_summary(state)
        except Exception:
            pass
        raise typer.Exit(code=130)


@app.command()
def status() -> None:
    """Display the current pipeline state.

    Reads the persisted pipeline state and prints a formatted
    summary including phases, builders, costs, and quality results.
    """
    try:
        state = PipelineState.load()
    except FileNotFoundError:
        print_error_panel(
            "No pipeline state found. Run 'init' or 'run' first."
        )
        raise typer.Exit(code=1)

    print_pipeline_header(state.pipeline_id, state.prd_path)
    print_phase_table(state)
    print_builder_table(state)

    # Show quality results if available
    if state.last_quality_results:
        print_quality_summary(state.last_quality_results)

    print_final_summary(state)


@app.command()
def resume(
    config_path: Annotated[
        Optional[Path],
        typer.Option("--config", "-c", help="Path to config YAML."),
    ] = None,
) -> None:
    """Resume an interrupted pipeline from the last saved state.

    Loads the persisted pipeline state and re-enters the pipeline
    loop at the interrupted phase using the RESUME_TRIGGERS map.
    """
    asyncio.run(_resume_async(config_path))


async def _resume_async(config_path: Path | None) -> None:
    """Async implementation of the resume command."""
    from src.super_orchestrator.pipeline import execute_pipeline

    try:
        state = PipelineState.load()
    except FileNotFoundError:
        print_error_panel(
            "No pipeline state found. Nothing to resume."
        )
        raise typer.Exit(code=1)

    if state.current_state in ("complete", "failed"):
        print_error_panel(
            f"Pipeline is in terminal state '{state.current_state}'. "
            "Cannot resume. Start a new run instead."
        )
        raise typer.Exit(code=1)

    typer.echo(f"Resuming pipeline {state.pipeline_id} from state '{state.current_state}'")
    print_pipeline_header(state.pipeline_id, state.prd_path)

    config_path_str = str(config_path) if config_path else state.config_path or None

    try:
        state = await execute_pipeline(
            prd_path=state.prd_path,
            config_path=config_path_str,
            resume=True,
        )
        print_final_summary(state)
    except PipelineError as exc:
        print_error_panel(str(exc))
        try:
            state = PipelineState.load()
            print_final_summary(state)
        except Exception:
            pass
        raise typer.Exit(code=1)
    except KeyboardInterrupt:
        typer.echo("\n[yellow]Pipeline interrupted. State saved.[/yellow]")
        raise typer.Exit(code=130)


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def _check_docker() -> bool:
    """Check if Docker Compose is available.

    Returns
    -------
    bool
        True if ``docker compose version`` succeeds.
    """
    try:
        result = subprocess.run(
            ["docker", "compose", "version"],
            capture_output=True,
            text=True,
            timeout=10,
        )
        return result.returncode == 0
    except (FileNotFoundError, subprocess.TimeoutExpired, OSError):
        return False


# ---------------------------------------------------------------------------
# Module entry point
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    app()
