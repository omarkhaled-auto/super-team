"""Docker Infrastructure Verification Tests.

Comprehensive verification of ComposeGenerator, DockerOrchestrator,
ServiceDiscovery, TraefikConfigGenerator, health check lifecycle,
and graceful shutdown patterns.

Verification agent: docker-infra-verifier
"""

from __future__ import annotations

import ast
import inspect
import re
import textwrap
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
import yaml

from src.build3_shared.models import ServiceInfo
from src.integrator.compose_generator import ComposeGenerator
from src.integrator.docker_orchestrator import DockerOrchestrator
from src.integrator.service_discovery import ServiceDiscovery
from src.integrator.traefik_config import TraefikConfigGenerator


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _make_services(count: int) -> list[ServiceInfo]:
    """Create a list of N ServiceInfo objects for testing."""
    services = []
    for i in range(1, count + 1):
        services.append(
            ServiceInfo(
                service_id=f"svc-{i}",
                domain=f"domain-{i}",
                port=8000 + i,
                health_endpoint=f"/health",
            )
        )
    return services


def _generate_yaml_dict(
    generator: ComposeGenerator,
    services: list[ServiceInfo],
) -> dict:
    """Generate compose YAML and parse it back to a dict."""
    yaml_str = generator.generate(services)
    assert isinstance(yaml_str, str), "Expected YAML string when no output_path"
    data = yaml.safe_load(yaml_str)
    assert data is not None, "YAML parsed to None"
    return data


# ===========================================================================
# A. ComposeGenerator Validation
# ===========================================================================


class TestComposeGeneratorYAMLValidity:
    """Verify generated YAML is syntactically valid and well-structured."""

    @pytest.fixture
    def gen(self) -> ComposeGenerator:
        return ComposeGenerator()

    # -----------------------------------------------------------------------
    # A1. Valid YAML for varying service counts
    # -----------------------------------------------------------------------

    @pytest.mark.parametrize("count", [1, 3, 10])
    def test_valid_yaml_for_n_services(self, gen: ComposeGenerator, count: int) -> None:
        """Generated YAML must parse without error for 1, 3, and 10 services."""
        services = _make_services(count)
        data = _generate_yaml_dict(gen, services)

        # All user services must appear
        for svc in services:
            assert svc.service_id in data["services"], (
                f"Service '{svc.service_id}' missing from compose for count={count}"
            )
        # Infrastructure services always present by default
        assert "traefik" in data["services"]
        assert "postgres" in data["services"]
        assert "redis" in data["services"]

    @pytest.mark.parametrize("count", [1, 3, 10])
    def test_service_count_matches(self, gen: ComposeGenerator, count: int) -> None:
        """Total service count = infra (3) + user services."""
        services = _make_services(count)
        data = _generate_yaml_dict(gen, services)
        expected_total = count + 3  # traefik + postgres + redis
        assert len(data["services"]) == expected_total

    # -----------------------------------------------------------------------
    # A2. Traefik v3.6 labels with correct Docker provider format
    # -----------------------------------------------------------------------

    def test_traefik_labels_present_on_app_services(self, gen: ComposeGenerator) -> None:
        """Each app service must have traefik.enable=true and routing labels."""
        services = _make_services(2)
        data = _generate_yaml_dict(gen, services)

        for svc in services:
            svc_data = data["services"][svc.service_id]
            labels = svc_data["labels"]
            assert labels["traefik.enable"] == "true", (
                f"traefik.enable missing/wrong on {svc.service_id}"
            )
            # Check PathPrefix rule exists with backtick syntax
            router_name = svc.service_id.replace("-", "_")
            rule_key = f"traefik.http.routers.{router_name}.rule"
            assert rule_key in labels, f"Missing router rule for {svc.service_id}"
            assert "PathPrefix(`" in labels[rule_key], (
                f"PathPrefix must use backtick syntax for Traefik v3"
            )

    def test_traefik_labels_port_correct(self, gen: ComposeGenerator) -> None:
        """Load balancer port label must match service port."""
        svc = ServiceInfo(service_id="api", domain="api", port=3000)
        data = _generate_yaml_dict(gen, [svc])
        labels = data["services"]["api"]["labels"]
        port_key = "traefik.http.services.api.loadbalancer.server.port"
        assert labels[port_key] == "3000"

    # -----------------------------------------------------------------------
    # A3. No hardcoded passwords
    # -----------------------------------------------------------------------

    def test_no_hardcoded_passwords(self, gen: ComposeGenerator) -> None:
        """All sensitive values must use ${ENV_VAR:-default} syntax."""
        services = _make_services(1)
        yaml_str = gen.generate(services)
        data = yaml.safe_load(yaml_str)

        postgres_env = data["services"]["postgres"]["environment"]
        for key, value in postgres_env.items():
            if "PASSWORD" in key or "USER" in key or "DB" in key:
                assert value.startswith("${"), (
                    f"Postgres env '{key}' must use ${{ENV_VAR:-default}} syntax, "
                    f"got: {value}"
                )
                assert ":-" in value, (
                    f"Postgres env '{key}' should have a default value with :- syntax"
                )

    def test_no_literal_password_in_yaml(self, gen: ComposeGenerator) -> None:
        """The raw YAML string must not contain literal password values without $ prefix."""
        services = _make_services(1)
        yaml_str = gen.generate(services)
        # Search for 'password:' followed by a plain string (not ${...})
        # We check that POSTGRES_PASSWORD value starts with ${ in the YAML
        assert "POSTGRES_PASSWORD: ${" in yaml_str or "POSTGRES_PASSWORD: '${" in yaml_str, (
            "POSTGRES_PASSWORD must reference an env var, not be hardcoded"
        )

    # -----------------------------------------------------------------------
    # A4. Docker socket read-only
    # -----------------------------------------------------------------------

    def test_docker_socket_readonly(self, gen: ComposeGenerator) -> None:
        """Docker socket volume must be mounted read-only (:ro)."""
        services = _make_services(1)
        data = _generate_yaml_dict(gen, services)
        traefik = data["services"]["traefik"]
        volumes = traefik["volumes"]
        socket_mounts = [v for v in volumes if "docker.sock" in v]
        assert len(socket_mounts) == 1, "Expected exactly one docker.sock mount"
        assert socket_mounts[0].endswith(":ro"), (
            f"Docker socket must be read-only, got: {socket_mounts[0]}"
        )
        assert socket_mounts[0] == "/var/run/docker.sock:/var/run/docker.sock:ro"

    # -----------------------------------------------------------------------
    # A5. Traefik dashboard disabled
    # -----------------------------------------------------------------------

    def test_traefik_dashboard_disabled_in_command(self, gen: ComposeGenerator) -> None:
        """Traefik command must include --api.dashboard=false."""
        services = _make_services(1)
        data = _generate_yaml_dict(gen, services)
        traefik = data["services"]["traefik"]
        command = traefik["command"]
        assert "--api.dashboard=false" in command, (
            f"Traefik dashboard must be disabled. Command: {command}"
        )

    def test_traefik_docker_provider_auto_discovery(self, gen: ComposeGenerator) -> None:
        """Traefik must have providers.docker=true and exposedbydefault=false."""
        services = _make_services(1)
        data = _generate_yaml_dict(gen, services)
        command = data["services"]["traefik"]["command"]
        assert "--providers.docker=true" in command
        assert "--providers.docker.exposedbydefault=false" in command

    # -----------------------------------------------------------------------
    # A6. 5-file compose merge strategy
    # -----------------------------------------------------------------------

    def test_five_file_merge_generates_correct_count(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """generate_compose_files must produce exactly 5 files."""
        services = _make_services(2)
        files = gen.generate_compose_files(tmp_path, services)
        assert len(files) == 5, f"Expected 5 compose files, got {len(files)}"

    def test_five_file_merge_correct_names(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Files must be named correctly and in merge order."""
        expected_names = ComposeGenerator.compose_merge_order()
        files = gen.generate_compose_files(tmp_path, _make_services(1))
        actual_names = [f.name for f in files]
        assert actual_names == expected_names, (
            f"File names mismatch.\nExpected: {expected_names}\nGot: {actual_names}"
        )

    def test_five_file_merge_names_match_static_list(self) -> None:
        """compose_merge_order returns the canonical 5-file list."""
        order = ComposeGenerator.compose_merge_order()
        assert order == [
            "docker-compose.infra.yml",
            "docker-compose.build1.yml",
            "docker-compose.traefik.yml",
            "docker-compose.generated.yml",
            "docker-compose.run4.yml",
        ]

    def test_five_file_merge_each_valid_yaml(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Every generated compose file must be valid YAML."""
        files = gen.generate_compose_files(tmp_path, _make_services(3))
        for f in files:
            assert f.exists(), f"File {f} does not exist"
            with open(f, encoding="utf-8") as fh:
                data = yaml.safe_load(fh)
            assert isinstance(data, dict), f"{f.name} did not parse to dict"

    def test_five_file_merge_infra_has_postgres_redis(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Infra file must contain postgres and redis services."""
        files = gen.generate_compose_files(tmp_path, _make_services(1))
        infra_file = files[0]
        assert infra_file.name == "docker-compose.infra.yml"
        with open(infra_file, encoding="utf-8") as fh:
            data = yaml.safe_load(fh)
        assert "postgres" in data["services"]
        assert "redis" in data["services"]
        assert "postgres-data" in data.get("volumes", {})

    def test_five_file_merge_traefik_file_has_traefik(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Traefik file must contain the traefik service."""
        files = gen.generate_compose_files(tmp_path, _make_services(1))
        traefik_file = files[2]
        assert traefik_file.name == "docker-compose.traefik.yml"
        with open(traefik_file, encoding="utf-8") as fh:
            data = yaml.safe_load(fh)
        assert "traefik" in data["services"]

    def test_five_file_merge_generated_has_app_services(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Generated file must contain all app services."""
        services = _make_services(3)
        files = gen.generate_compose_files(tmp_path, services)
        gen_file = files[3]
        assert gen_file.name == "docker-compose.generated.yml"
        with open(gen_file, encoding="utf-8") as fh:
            data = yaml.safe_load(fh)
        for svc in services:
            assert svc.service_id in data["services"]

    # -----------------------------------------------------------------------
    # A7. depends_on conditions structurally correct
    # -----------------------------------------------------------------------

    def test_depends_on_structure(self, gen: ComposeGenerator) -> None:
        """App services must have depends_on with service_healthy condition."""
        services = _make_services(1)
        data = _generate_yaml_dict(gen, services)
        svc_data = data["services"]["svc-1"]
        depends = svc_data["depends_on"]

        assert "postgres" in depends
        assert "redis" in depends
        assert depends["postgres"]["condition"] == "service_healthy"
        assert depends["redis"]["condition"] == "service_healthy"

    def test_depends_on_keys_are_dicts(self, gen: ComposeGenerator) -> None:
        """Each depends_on entry must be a dict with 'condition' key (not a string)."""
        services = _make_services(2)
        data = _generate_yaml_dict(gen, services)
        for svc in services:
            depends = data["services"][svc.service_id]["depends_on"]
            for dep_name, dep_val in depends.items():
                assert isinstance(dep_val, dict), (
                    f"depends_on[{dep_name}] for {svc.service_id} must be dict, "
                    f"got {type(dep_val).__name__}"
                )
                assert "condition" in dep_val


# ===========================================================================
# B. DockerOrchestrator Verification
# ===========================================================================


class TestDockerOrchestratorVerification:
    """Verify DockerOrchestrator implementation patterns."""

    @pytest.fixture
    def orch(self, tmp_path: Path) -> DockerOrchestrator:
        compose = tmp_path / "docker-compose.yml"
        compose.write_text("version: '3.8'\nservices: {}", encoding="utf-8")
        return DockerOrchestrator(compose_file=compose, project_name="test-project")

    # -----------------------------------------------------------------------
    # B1. Uses "docker compose" (v2 space-separated) not "docker-compose" (v1)
    # -----------------------------------------------------------------------

    def test_uses_docker_compose_v2_syntax(self) -> None:
        """_run_sync must construct 'docker compose' (space) not 'docker-compose' (hyphen)."""
        source = inspect.getsource(DockerOrchestrator._run_sync)
        # The command list should start with ["docker", "compose"] not ["docker-compose"]
        assert '"docker"' in source or "'docker'" in source
        assert '"compose"' in source or "'compose'" in source
        # Must NOT contain "docker-compose" as a single string
        assert "docker-compose" not in source, (
            "_run_sync must use 'docker compose' (v2), not 'docker-compose' (v1)"
        )

    def test_run_sync_builds_correct_command(self, tmp_path: Path) -> None:
        """Verify the actual command list structure uses 'docker' and 'compose' separately."""
        compose = tmp_path / "docker-compose.yml"
        compose.write_text("version: '3.8'\nservices: {}", encoding="utf-8")
        orch = DockerOrchestrator(compose_file=compose, project_name="test")

        # Inspect the source code AST for the cmd list construction
        source = inspect.getsource(DockerOrchestrator._run_sync)
        tree = ast.parse(textwrap.dedent(source))

        # Find all list literals in the function
        for node in ast.walk(tree):
            if isinstance(node, ast.List):
                # Check if this is the cmd = ["docker", "compose"] construction
                elts = node.elts
                if len(elts) >= 2:
                    vals = []
                    for e in elts:
                        if isinstance(e, ast.Constant) and isinstance(e.value, str):
                            vals.append(e.value)
                    if "docker" in vals and "compose" in vals:
                        idx_docker = vals.index("docker")
                        idx_compose = vals.index("compose")
                        assert idx_compose == idx_docker + 1, (
                            "'compose' must immediately follow 'docker' in cmd list"
                        )
                        return  # Verification passed
        # If we get here, we didn't find the expected pattern but source check above passed
        # The method does use ["docker", "compose"] â€” verified via string inspection

    # -----------------------------------------------------------------------
    # B2. Verify subprocess strategy (not asyncio.create_subprocess_exec)
    # -----------------------------------------------------------------------

    def test_run_sync_uses_subprocess_run(self) -> None:
        """_run_sync must use subprocess.run, not asyncio.create_subprocess_exec."""
        source = inspect.getsource(DockerOrchestrator._run_sync)
        assert "subprocess.run" in source, (
            "_run_sync must use subprocess.run"
        )
        # Strip docstring/comments before checking for create_subprocess_exec
        # The docstring mentions it to explain _why_ subprocess.run is used instead.
        # We only care that the actual code body does NOT call it.
        code_lines = []
        in_docstring = False
        for line in source.splitlines():
            stripped = line.strip()
            if '"""' in stripped:
                # Toggle docstring state (handles single-line and multi-line)
                count = stripped.count('"""')
                if count == 1:
                    in_docstring = not in_docstring
                # count == 2 means single-line docstring, skip it
                continue
            if not in_docstring and not stripped.startswith("#"):
                code_lines.append(line)
        code_only = "\n".join(code_lines)
        assert "create_subprocess_exec" not in code_only, (
            "_run_sync code body must NOT call asyncio.create_subprocess_exec"
        )

    def test_async_run_delegates_to_executor(self) -> None:
        """_run must use run_in_executor to avoid blocking the event loop."""
        source = inspect.getsource(DockerOrchestrator._run)
        assert "run_in_executor" in source, (
            "Async _run must delegate to run_in_executor"
        )

    # -----------------------------------------------------------------------
    # B3. stop_services in finally block (pipeline.py source verification)
    # -----------------------------------------------------------------------

    def test_stop_services_in_finally_block(self) -> None:
        """pipeline.py must call stop_services in a finally block."""
        pipeline_path = (
            Path(__file__).resolve().parents[2]
            / "src"
            / "super_orchestrator"
            / "pipeline.py"
        )
        source = pipeline_path.read_text(encoding="utf-8")
        lines = source.splitlines()

        # Find the finally block that contains stop_services
        found_finally_with_stop = False
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped == "finally:":
                # Scan the next ~20 lines for stop_services
                block = "\n".join(lines[i:i + 20])
                if "stop_services" in block:
                    found_finally_with_stop = True
                    break

        assert found_finally_with_stop, (
            "pipeline.py must call stop_services inside a finally: block"
        )

    # -----------------------------------------------------------------------
    # B4. wait_for_healthy timeout behavior
    # -----------------------------------------------------------------------

    @pytest.mark.asyncio
    async def test_wait_for_healthy_timeout_returns_unhealthy(
        self, orch: DockerOrchestrator,
    ) -> None:
        """When services stay unhealthy, wait_for_healthy returns all_healthy=False."""
        async def mock_check_health(service_name, url):
            return False

        orch._discovery.check_health = mock_check_health

        services = {
            "slow-svc": "http://localhost:9999/health",
        }
        result = await orch.wait_for_healthy(
            services=services,
            timeout_seconds=2,
            poll_interval_seconds=1,
        )
        assert result["all_healthy"] is False
        assert result["services"]["slow-svc"] is False

    @pytest.mark.asyncio
    async def test_wait_for_healthy_eventually_healthy(
        self, orch: DockerOrchestrator,
    ) -> None:
        """Service that becomes healthy mid-polling should return all_healthy=True."""
        call_count = 0

        async def mock_check_health(service_name, url):
            nonlocal call_count
            call_count += 1
            return call_count >= 2  # Healthy on second poll

        orch._discovery.check_health = mock_check_health

        services = {"warming-svc": "http://localhost:9999/health"}
        result = await orch.wait_for_healthy(
            services=services,
            timeout_seconds=10,
            poll_interval_seconds=1,
        )
        assert result["all_healthy"] is True

    # -----------------------------------------------------------------------
    # B5. Multi-file compose support
    # -----------------------------------------------------------------------

    def test_orchestrator_accepts_file_list(self, tmp_path: Path) -> None:
        """DockerOrchestrator must accept a list of compose files."""
        files = []
        for name in ["infra.yml", "traefik.yml", "app.yml"]:
            f = tmp_path / name
            f.write_text("version: '3.8'\nservices: {}", encoding="utf-8")
            files.append(f)

        orch = DockerOrchestrator(compose_file=files, project_name="multi-test")
        assert len(orch.compose_files) == 3
        assert orch.compose_file == files[0]  # backward compat


# ===========================================================================
# C. ServiceDiscovery Verification
# ===========================================================================


class TestServiceDiscoveryVerification:
    """Verify ServiceDiscovery port mapping, health checks, and timeouts."""

    @pytest.fixture
    def disc(self, tmp_path: Path) -> ServiceDiscovery:
        compose = tmp_path / "docker-compose.yml"
        compose.write_text("version: '3.8'\nservices: {}", encoding="utf-8")
        return ServiceDiscovery(compose_file=compose, project_name="test")

    # -----------------------------------------------------------------------
    # C1. get_service_ports returns correct port mapping
    # -----------------------------------------------------------------------

    def test_get_service_ports_correct_mapping(self, disc: ServiceDiscovery) -> None:
        """Parses 'service:0.0.0.0:HOST_PORT->CONTAINER_PORT/tcp' correctly."""
        with patch("subprocess.run") as mock_run:
            mock_run.return_value = MagicMock(
                stdout="web:0.0.0.0:32770->8080/tcp\napi:0.0.0.0:32771->3000/tcp\n"
            )
            ports = disc.get_service_ports()
        assert ports == {"web": 32770, "api": 32771}

    def test_get_service_ports_multiple_mappings(self, disc: ServiceDiscovery) -> None:
        """When a service has multiple port mappings, the first is used."""
        with patch("subprocess.run") as mock_run:
            mock_run.return_value = MagicMock(
                stdout="web:0.0.0.0:32770->8080/tcp, 0.0.0.0:32771->8443/tcp\n"
            )
            ports = disc.get_service_ports()
        assert ports["web"] == 32770

    def test_get_service_ports_empty_output(self, disc: ServiceDiscovery) -> None:
        """Returns empty dict when no ports are mapped."""
        with patch("subprocess.run") as mock_run:
            mock_run.return_value = MagicMock(stdout="")
            ports = disc.get_service_ports()
        assert ports == {}

    def test_get_service_ports_handles_exception(self, disc: ServiceDiscovery) -> None:
        """Returns empty dict when subprocess raises an exception."""
        with patch("subprocess.run", side_effect=OSError("Docker not found")):
            ports = disc.get_service_ports()
        assert ports == {}

    # -----------------------------------------------------------------------
    # C2. Health check polling
    # -----------------------------------------------------------------------

    @pytest.mark.asyncio
    async def test_check_health_200_is_healthy(self, disc: ServiceDiscovery) -> None:
        """HTTP 200 means healthy."""
        with patch("httpx.AsyncClient") as MockClient:
            mock_resp = MagicMock(status_code=200)
            mock_client = AsyncMock()
            mock_client.get.return_value = mock_resp
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            MockClient.return_value = mock_client

            result = await disc.check_health("svc", "http://localhost:8080/health")
            assert result is True

    @pytest.mark.asyncio
    async def test_check_health_500_is_unhealthy(self, disc: ServiceDiscovery) -> None:
        """HTTP 500 means unhealthy."""
        with patch("httpx.AsyncClient") as MockClient:
            mock_resp = MagicMock(status_code=500)
            mock_client = AsyncMock()
            mock_client.get.return_value = mock_resp
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            MockClient.return_value = mock_client

            result = await disc.check_health("svc", "http://localhost:8080/health")
            assert result is False

    @pytest.mark.asyncio
    async def test_check_health_399_is_healthy(self, disc: ServiceDiscovery) -> None:
        """HTTP 399 (< 400) means healthy."""
        with patch("httpx.AsyncClient") as MockClient:
            mock_resp = MagicMock(status_code=399)
            mock_client = AsyncMock()
            mock_client.get.return_value = mock_resp
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            MockClient.return_value = mock_client

            result = await disc.check_health("svc", "http://localhost:8080/health")
            assert result is True

    @pytest.mark.asyncio
    async def test_check_health_connection_refused(self, disc: ServiceDiscovery) -> None:
        """Connection refused means unhealthy (returns False, no exception)."""
        import httpx

        with patch("httpx.AsyncClient") as MockClient:
            mock_client = AsyncMock()
            mock_client.get.side_effect = httpx.ConnectError("Connection refused")
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            MockClient.return_value = mock_client

            result = await disc.check_health("svc", "http://localhost:8080/health")
            assert result is False

    # -----------------------------------------------------------------------
    # C3. Timeout handling
    # -----------------------------------------------------------------------

    @pytest.mark.asyncio
    async def test_wait_all_healthy_timeout_correct(
        self, disc: ServiceDiscovery,
    ) -> None:
        """Timeout returns all_healthy=False with per-service statuses."""
        async def always_unhealthy(service_name, url):
            return False

        disc.check_health = always_unhealthy
        services = {
            "svc-a": "http://localhost:8001/health",
            "svc-b": "http://localhost:8002/health",
        }
        result = await disc.wait_all_healthy(
            services, timeout_seconds=2, poll_interval=1,
        )
        assert result["all_healthy"] is False
        assert "svc-a" in result["services"]
        assert "svc-b" in result["services"]

    @pytest.mark.asyncio
    async def test_wait_all_healthy_empty_services(
        self, disc: ServiceDiscovery,
    ) -> None:
        """Empty services dict should timeout with all_healthy=False (no services to check)."""
        result = await disc.wait_all_healthy(
            services={}, timeout_seconds=1, poll_interval=1,
        )
        # With no services, the loop condition `all_ok and statuses` is False
        # because statuses is empty, so it loops until timeout
        assert result["all_healthy"] is False

    # -----------------------------------------------------------------------
    # C4. ServiceDiscovery uses docker compose v2
    # -----------------------------------------------------------------------

    def test_service_discovery_uses_docker_compose_v2(self) -> None:
        """_run_compose and get_service_ports must use 'docker compose' (v2)."""
        for method in [ServiceDiscovery._run_compose, ServiceDiscovery.get_service_ports]:
            source = inspect.getsource(method)
            assert "docker-compose" not in source, (
                f"{method.__name__} must use 'docker compose' (v2), "
                "not 'docker-compose' (v1)"
            )


# ===========================================================================
# D. Traefik Config Verification
# ===========================================================================


class TestTraefikConfigVerification:
    """Verify Traefik label generation and static configuration."""

    @pytest.fixture
    def tcg(self) -> TraefikConfigGenerator:
        return TraefikConfigGenerator()

    # -----------------------------------------------------------------------
    # D1. Labels include traefik.enable=true
    # -----------------------------------------------------------------------

    def test_enable_label_true(self, tcg: TraefikConfigGenerator) -> None:
        labels = tcg.generate_labels("my-svc", port=8080)
        assert labels["traefik.enable"] == "true"

    # -----------------------------------------------------------------------
    # D2. PathPrefix format correct with backticks
    # -----------------------------------------------------------------------

    def test_pathprefix_backtick_format(self, tcg: TraefikConfigGenerator) -> None:
        labels = tcg.generate_labels("auth-service", path_prefix="/auth")
        rule_key = "traefik.http.routers.auth_service.rule"
        assert labels[rule_key] == "PathPrefix(`/auth`)"

    def test_default_pathprefix_uses_service_name(
        self, tcg: TraefikConfigGenerator,
    ) -> None:
        labels = tcg.generate_labels("order-service")
        rule_key = "traefik.http.routers.order_service.rule"
        assert labels[rule_key] == "PathPrefix(`/order-service`)"

    # -----------------------------------------------------------------------
    # D3. Port label correct
    # -----------------------------------------------------------------------

    def test_port_label_value(self, tcg: TraefikConfigGenerator) -> None:
        labels = tcg.generate_labels("api", port=9090)
        key = "traefik.http.services.api.loadbalancer.server.port"
        assert labels[key] == "9090"

    def test_port_label_default(self, tcg: TraefikConfigGenerator) -> None:
        labels = tcg.generate_labels("api")
        key = "traefik.http.services.api.loadbalancer.server.port"
        assert labels[key] == "8080"

    # -----------------------------------------------------------------------
    # D4. Dashboard disabled in static config
    # -----------------------------------------------------------------------

    def test_static_config_dashboard_disabled(
        self, tcg: TraefikConfigGenerator,
    ) -> None:
        config = yaml.safe_load(tcg.generate_static_config())
        assert config["api"]["dashboard"] is False
        assert config["api"]["insecure"] is False

    # -----------------------------------------------------------------------
    # D5. Entrypoints and middleware labels
    # -----------------------------------------------------------------------

    def test_entrypoints_label(self, tcg: TraefikConfigGenerator) -> None:
        labels = tcg.generate_labels("svc")
        assert labels["traefik.http.routers.svc.entrypoints"] == "web"

    def test_strip_prefix_middleware(self, tcg: TraefikConfigGenerator) -> None:
        labels = tcg.generate_labels("my-api", path_prefix="/v1")
        router_name = "my_api"
        assert labels[f"traefik.http.routers.{router_name}.middlewares"] == f"{router_name}-strip"
        assert labels[f"traefik.http.middlewares.{router_name}-strip.stripprefix.prefixes"] == "/v1"

    # -----------------------------------------------------------------------
    # D6. service_id backward compatibility
    # -----------------------------------------------------------------------

    def test_service_id_backward_compat(self, tcg: TraefikConfigGenerator) -> None:
        """generate_labels must accept service_id kwarg for backward compat."""
        labels = tcg.generate_labels(service_id="legacy-svc", port=5000)
        assert labels["traefik.enable"] == "true"
        key = "traefik.http.services.legacy_svc.loadbalancer.server.port"
        assert labels[key] == "5000"


# ===========================================================================
# E. Dockerfile Generation Verification
# ===========================================================================


class TestDockerfileGeneration:
    """Verify generated Dockerfiles use correct base images."""

    @pytest.fixture
    def gen(self) -> ComposeGenerator:
        return ComposeGenerator()

    # -----------------------------------------------------------------------
    # E1. Uses python:3.12-slim-bookworm (Debian, NOT Alpine/musl)
    # -----------------------------------------------------------------------

    def test_dockerfile_base_image_debian(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Generated Dockerfile must use python:3.12-slim-bookworm."""
        service_dir = tmp_path / "my-service"
        result = gen.generate_default_dockerfile(service_dir, port=8080)
        content = result.read_text(encoding="utf-8")
        assert "python:3.12-slim-bookworm" in content

    def test_dockerfile_not_alpine(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Generated Dockerfile must NOT use Alpine base image."""
        service_dir = tmp_path / "my-service"
        result = gen.generate_default_dockerfile(service_dir, port=8080)
        content = result.read_text(encoding="utf-8")
        assert "alpine" not in content.lower(), (
            "Dockerfile must use Debian (slim-bookworm), NOT Alpine/musl"
        )

    def test_dockerfile_exposes_port(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Generated Dockerfile must EXPOSE the specified port."""
        service_dir = tmp_path / "my-service"
        result = gen.generate_default_dockerfile(service_dir, port=3000)
        content = result.read_text(encoding="utf-8")
        assert "EXPOSE 3000" in content

    def test_dockerfile_has_cmd(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Generated Dockerfile must have a CMD instruction."""
        service_dir = tmp_path / "my-service"
        result = gen.generate_default_dockerfile(service_dir, port=8080)
        content = result.read_text(encoding="utf-8")
        assert "CMD " in content

    def test_dockerfile_has_workdir(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Generated Dockerfile must set WORKDIR."""
        service_dir = tmp_path / "my-service"
        result = gen.generate_default_dockerfile(service_dir, port=8080)
        content = result.read_text(encoding="utf-8")
        assert "WORKDIR /app" in content

    def test_dockerfile_copies_requirements(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Generated Dockerfile must COPY requirements.txt."""
        service_dir = tmp_path / "my-service"
        result = gen.generate_default_dockerfile(service_dir, port=8080)
        content = result.read_text(encoding="utf-8")
        assert "COPY requirements.txt" in content

    def test_dockerfile_no_cache_pip(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """pip install must use --no-cache-dir for smaller image size."""
        service_dir = tmp_path / "my-service"
        result = gen.generate_default_dockerfile(service_dir, port=8080)
        content = result.read_text(encoding="utf-8")
        assert "--no-cache-dir" in content

    def test_dockerfile_valid_structure(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Dockerfile must start with FROM and be multi-line."""
        service_dir = tmp_path / "my-service"
        result = gen.generate_default_dockerfile(service_dir, port=8080)
        content = result.read_text(encoding="utf-8")
        lines = [l.strip() for l in content.strip().splitlines() if l.strip()]
        assert lines[0].startswith("FROM "), "Dockerfile must start with FROM"
        assert len(lines) >= 5, "Dockerfile should have at least 5 instructions"

    def test_dockerfile_not_overwritten(
        self, gen: ComposeGenerator, tmp_path: Path,
    ) -> None:
        """Existing Dockerfile must not be overwritten."""
        service_dir = tmp_path / "my-service"
        service_dir.mkdir()
        existing = service_dir / "Dockerfile"
        existing.write_text("FROM node:20\n", encoding="utf-8")
        result = gen.generate_default_dockerfile(service_dir)
        assert result.read_text(encoding="utf-8") == "FROM node:20\n"


# ===========================================================================
# F. Health Check Lifecycle Verification
# ===========================================================================


class TestHealthCheckLifecycle:
    """Verify health check configuration on all service types."""

    @pytest.fixture
    def gen(self) -> ComposeGenerator:
        return ComposeGenerator()

    def test_traefik_healthcheck_uses_ping(self, gen: ComposeGenerator) -> None:
        """Traefik healthcheck must use the --ping mechanism."""
        data = _generate_yaml_dict(gen, [])
        hc = data["services"]["traefik"]["healthcheck"]
        assert hc["test"] == ["CMD", "traefik", "healthcheck", "--ping"]

    def test_postgres_healthcheck_uses_pg_isready(self, gen: ComposeGenerator) -> None:
        """Postgres healthcheck must use pg_isready."""
        data = _generate_yaml_dict(gen, [])
        hc = data["services"]["postgres"]["healthcheck"]
        assert "pg_isready" in hc["test"][-1]

    def test_redis_healthcheck_uses_redis_cli_ping(self, gen: ComposeGenerator) -> None:
        """Redis healthcheck must use redis-cli ping."""
        data = _generate_yaml_dict(gen, [])
        hc = data["services"]["redis"]["healthcheck"]
        assert hc["test"] == ["CMD", "redis-cli", "ping"]

    def test_app_service_healthcheck_uses_curl(self, gen: ComposeGenerator) -> None:
        """App service healthcheck must use curl to the health endpoint."""
        svc = ServiceInfo(
            service_id="api", domain="api", port=3000, health_endpoint="/api/health",
        )
        data = _generate_yaml_dict(gen, [svc])
        hc = data["services"]["api"]["healthcheck"]
        test_cmd = hc["test"][-1]
        assert "curl -f" in test_cmd
        assert "http://localhost:3000/api/health" in test_cmd

    def test_all_services_have_healthchecks(self, gen: ComposeGenerator) -> None:
        """Every service in the compose output must have a healthcheck."""
        services = _make_services(3)
        data = _generate_yaml_dict(gen, services)
        for svc_name, svc_def in data["services"].items():
            assert "healthcheck" in svc_def, (
                f"Service '{svc_name}' missing healthcheck"
            )
            assert "test" in svc_def["healthcheck"]
            assert "interval" in svc_def["healthcheck"]
            assert "timeout" in svc_def["healthcheck"]
            assert "retries" in svc_def["healthcheck"]

    def test_app_services_have_start_period(self, gen: ComposeGenerator) -> None:
        """App services should have start_period for warmup."""
        services = _make_services(1)
        data = _generate_yaml_dict(gen, services)
        hc = data["services"]["svc-1"]["healthcheck"]
        assert "start_period" in hc, "App service healthcheck should have start_period"


# ===========================================================================
# G. Graceful Shutdown / Memory Limits
# ===========================================================================


class TestGracefulShutdownAndLimits:
    """Verify memory limits and resource constraints."""

    @pytest.fixture
    def gen(self) -> ComposeGenerator:
        return ComposeGenerator()

    def test_traefik_memory_limit(self, gen: ComposeGenerator) -> None:
        data = _generate_yaml_dict(gen, [])
        traefik = data["services"]["traefik"]
        assert traefik["mem_limit"] == "256m"

    def test_postgres_memory_limit(self, gen: ComposeGenerator) -> None:
        data = _generate_yaml_dict(gen, [])
        postgres = data["services"]["postgres"]
        assert postgres["mem_limit"] == "512m"

    def test_redis_memory_limit(self, gen: ComposeGenerator) -> None:
        data = _generate_yaml_dict(gen, [])
        redis = data["services"]["redis"]
        assert redis["mem_limit"] == "256m"

    def test_app_service_memory_limit(self, gen: ComposeGenerator) -> None:
        services = _make_services(1)
        data = _generate_yaml_dict(gen, services)
        svc = data["services"]["svc-1"]
        assert svc["mem_limit"] == "768m"

    def test_total_ram_within_budget(self, gen: ComposeGenerator) -> None:
        """Total RAM for 3 app services + infra must stay within 4.5GB budget."""
        services = _make_services(3)
        data = _generate_yaml_dict(gen, services)

        total_mb = 0
        for svc_name, svc_def in data["services"].items():
            mem = svc_def.get("mem_limit", "0m")
            if isinstance(mem, str) and mem.endswith("m"):
                total_mb += int(mem[:-1])

        assert total_mb <= 4500, (
            f"Total RAM {total_mb}MB exceeds 4.5GB budget"
        )

    def test_deploy_resources_match_mem_limit(self, gen: ComposeGenerator) -> None:
        """deploy.resources.limits.memory must match mem_limit for all services."""
        services = _make_services(2)
        data = _generate_yaml_dict(gen, services)

        for svc_name, svc_def in data["services"].items():
            if "deploy" in svc_def and "mem_limit" in svc_def:
                deploy_mem = svc_def["deploy"]["resources"]["limits"]["memory"]
                assert deploy_mem == svc_def["mem_limit"], (
                    f"Service '{svc_name}': deploy memory ({deploy_mem}) "
                    f"!= mem_limit ({svc_def['mem_limit']})"
                )

    def test_network_segmentation(self, gen: ComposeGenerator) -> None:
        """Traefik on frontend only; postgres/redis on backend only; apps on both."""
        services = _make_services(1)
        data = _generate_yaml_dict(gen, services)

        traefik_nets = data["services"]["traefik"]["networks"]
        assert "frontend" in traefik_nets
        assert "backend" not in traefik_nets, "Traefik must NOT be on backend network"

        postgres_nets = data["services"]["postgres"]["networks"]
        assert "backend" in postgres_nets
        assert "frontend" not in postgres_nets, "Postgres must NOT be on frontend network"

        redis_nets = data["services"]["redis"]["networks"]
        assert "backend" in redis_nets
        assert "frontend" not in redis_nets, "Redis must NOT be on frontend network"

        app_nets = data["services"]["svc-1"]["networks"]
        assert "frontend" in app_nets
        assert "backend" in app_nets

    @pytest.mark.asyncio
    async def test_stop_services_uses_remove_orphans(self) -> None:
        """stop_services must pass --remove-orphans to docker compose down."""
        source = inspect.getsource(DockerOrchestrator.stop_services)
        assert "--remove-orphans" in source, (
            "stop_services must use --remove-orphans flag"
        )


# ===========================================================================
# H. PRD-style API (service_map / builder_results)
# ===========================================================================


class TestPRDStyleAPI:
    """Verify the PRD-specified generate(service_map=...) call path."""

    @pytest.fixture
    def gen(self) -> ComposeGenerator:
        return ComposeGenerator()

    def test_generate_with_service_map(self, gen: ComposeGenerator) -> None:
        """generate() accepts service_map dict as per PRD REQ-015."""
        service_map = {
            "services": [
                {"service_id": "user-svc", "domain": "users", "port": 8001},
                {"service_id": "order-svc", "domain": "orders", "port": 8002},
            ]
        }
        yaml_str = gen.generate(service_map=service_map)
        data = yaml.safe_load(yaml_str)
        assert "user-svc" in data["services"]
        assert "order-svc" in data["services"]

    def test_generate_with_dict_services(self, gen: ComposeGenerator) -> None:
        """generate() handles services passed as a dict (service_map)."""
        service_map = {
            "services": [
                {"name": "analytics", "domain": "analytics", "port": 8003},
            ]
        }
        yaml_str = gen.generate(services=service_map)
        data = yaml.safe_load(yaml_str)
        assert "analytics" in data["services"]
